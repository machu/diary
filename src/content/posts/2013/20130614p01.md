---
title: ログ収集＆分析サービス Treasure Data を試してみた
date: 2013-06-14T00:00:00.000Z
lastmod: 2014-05-21T01:43:47.000Z
draft: false
tags:
  - memo
  - Apache
---

最近、 [LTSV](http://ltsv.org/) や [fluentd](http://fluentd.org/) など、ログ分析が賑わっているので、試しに使ってみたい。といっても、自前でログを貯めこむ仕組みを作るのは大変なので、ログの収集・分析をしてくれる [Treasure Data](http://www.treasure-data.com/) を試してみた。

[![Treasure Data](https://farm4.staticflickr.com/3700/9046208184_ce6e23b6f2_z.jpg "Treasure Data")](http://www.flickr.com/photos/machu/9046208184/)

Treasure Data についてはこちらの記事が参考になる。

* [ターゲットは国内製造業のビッグデータ!? Treasure Dataがトレジャーデータとなって日本市場で本格展開：レポート｜gihyo.jp … 技術評論社](http://gihyo.jp/news/report/2013/05/2101)
* [Treasure Data - naoyaのはてなダイアリー](http://d.hatena.ne.jp/naoya/20130322/1363946401)

> 本当にごくごく単純化して言うとTDは「手元のサーバーとかからログをどんどん送りつけておくとそれを保存しといてくれて、SQL を投げると MapReduce で大規模並列にそれを実行して結果だけ返してくれるクラウドなサービス」です。

[無料プラン](http://www.treasure-data.com/pricing/)でも150GB, 60クエリ/月までは使える。さくらのVPSサーバにインストールして、Webサーバのログを Treasure Data に保存してみよう。OSはUbuntu 12.04 LTS を使っている。

#### インストール

[Quickstart Guide | Treasure Data](http://docs.treasure-data.com/articles/quickstart) に沿って進める。

```
$ curl -L http://toolbelt.treasure-data.com/sh/install-ubuntu-precise.sh | sh
```

ps コマンドで td-agent プロセスを確認すると、同梱の ruby で動いていることがわかる。

td-agent 6612 0.0 0.0 98900 892 ? Sl Jun14 0:00 /usr/lib/fluent/ruby/bin/ruby /usr/sbin/td-agent --daemon /var/run/td-agent/td-agent.pid --log /var/log/td-agent/td-agent.log

アカウントを設定して、データベースとテーブルを作成する。

```
$ td account
$ td db:create apache
$ td table:create apache access
```

#### Apache ログをインポート

手元にある Apache のアクセスログをインポートする。圧縮前のログも圧縮後のログも一緒に取り込めるので便利。ログをパースし、一定数が貯まると Treasure Data に送っているみたい。

```
$ td table:import apache access --apache /var/log/apache2/access.log*
importing access.log.11.gz...
  imported 10000 entries from access.log.11.gz...
  imported 20000 entries from access.log.11.gz...
  imported 30000 entries from access.log.11.gz...
  imported 40000 entries from access.log.11.gz...
  imported 47396 entries from access.log.11.gz...
  uploading 1073917 bytes...
```

ログは 450MB 分 (1600万行) あるので、取り込みにはちょっと時間がかかる。

#### Apache ログをリアルタイムで取り込み

td-agent は tail を使ってリアルタイムでログを取り込むことができる。やり方は [Analyzing Apache Logs on the Cloud | Treasure Data](http://docs.treasure-data.com/articles/analyzing-apache-logs) を参照。 `/etc/td-agent/td-agent.conf` に設定する。

```
<match td.*.*>
  type tdlog
  apikey ***********************

  auto_create_table
  buffer_type file
  buffer_path /var/log/td-agent/buffer/td
</match>

## File input
## read apache logs continuously and tags td.apache.access
<source>
  type tail
  format apache
  path /var/log/apache2/access.log
  tag td.apache.access
</source>
```

apikey は `td apikey` コマンドで確認できる。

このままだと、 td-agent ユーザが /var/log/apache2 への読み込み権限が無いので、 adm グループに追加しておく。

```
$ sudo usermod -G adm td-agent
```

#### ログ解析

同じページの Sample Queries に、ログ解析のサンプルクエリがある。たとえば、アクセス数の上位100件を抽出するクエリは、こんな感じ。

```
SELECT
    v[ 'path' ] AS PATH
    ,COUNT( 1 ) AS cnt
  FROM
    access
  GROUP BY
    v[ 'path' ]
  ORDER BY
    cnt DESC LIMIT 100
```

バックエンドのジョブで処理され、結果がテキストやCSVで返ってくる。 自分で解析プログラムを書くよりずっと楽だ。Map & Reduce で処理されていて、結果が返ってくるまで1分くらいかかる（無料プランだし）ので、リアルタイムにログを解析するよりも、毎日の集計処理に向いている。ログの量が増えても、同じ仕組みで処理できるのはいいね。

[Heroku の addon](https://addons.heroku.com/treasure-data) もあるようなので、 [Amazon API 認証リバースプロキシ](http://www.machu.jp/diary/20110925.html#p01) のログも Treasure Data に送るようにしてみるかな（いまは MongoHQ に保存している）。
